#####
##### The identity scope we are operating in
##### Used to add tge OpenStack user name to instance metadata
#####
data "openstack_identity_auth_scope_v3" "scope" {
  name = "{{ cluster_name }}"
}

#####
##### Security groups
#####

# Security group to hold rules for the node
resource "openstack_networking_secgroup_v2" "cluster_secgroup" {
  name                 = "{{ cluster_name }}-{{ cluster_type }}"
  delete_default_rules = true   # Fully manage with terraform
}

# Allow all egress
resource "openstack_networking_secgroup_rule_v2" "cluster_egress_v4" {
  direction         = "egress"
  ethertype         = "IPv4"
  security_group_id = "${openstack_networking_secgroup_v2.cluster_secgroup.id}"
}

{% if cluster_user_ssh_public_key is defined and cluster_user_ssh_public_key %}
# Allow ingress for SSH
resource "openstack_networking_secgroup_rule_v2" "cluster_ingress_ssh_v4" {
  direction         = "ingress"
  ethertype         = "IPv4"
  protocol          = "tcp"
  port_range_min    = 22
  port_range_max    = 22
  security_group_id = "${openstack_networking_secgroup_v2.cluster_secgroup.id}"
}
{% endif %}

#####
##### Cluster volumes
#####

resource "openstack_blockstorage_volume_v3" "zenith_volume" {
  name = "{{ cluster_name }}-{{ cluster_type }}-zenith"
  size = "{{ zenith_volume_size }}"
}

resource "openstack_blockstorage_volume_v3" "data_volume" {
  name = "{{ cluster_name }}-{{ cluster_type }}-data"
  size = "{{ cluster_volume_size }}"
  {% if use_cluster_volume_type_fast is defined and use_cluster_volume_type_fast %}
  {% if cluster_volume_type_fast is defined %}
  volume_type = "{{ cluster_volume_type_fast }}"
  {% endif %}
  {% endif %}
}

#####
##### Cluster networks
#####

# Get existing network resource data by name
data "openstack_networking_network_v2" "cluster_network" {
  name = "{{ cluster_network }}"
}

# Storage network 
{% if cluster_storage_network is defined %}
data "openstack_networking_network_v2" "cluster_storage" {
  name = "{{ cluster_storage_network }}"
}
{% endif %}

#####
##### Cluster ports
#####

# Primary network
resource "openstack_networking_port_v2" "cluster" {
  name = "{{ cluster_name }}"
  network_id = "${data.openstack_networking_network_v2.cluster_network.id}"
  admin_state_up = "true"

  security_group_ids = [
    "${openstack_networking_secgroup_v2.cluster_secgroup.id}",
  ]

  binding {
    vnic_type = "{{ cluster_vnic_type | default('normal') }}"
  }
}

# Storage network
{% if cluster_storage_network is defined %}
resource "openstack_networking_port_v2" "cluster_storage" {
  name           = "{{ cluster_name }}-storage"
  network_id     = data.openstack_networking_network_v2.cluster_storage.id
  admin_state_up = "true"

  security_group_ids = [
    "${openstack_networking_secgroup_v2.cluster_secgroup.id}",
  ]

  binding {
    vnic_type = "{{ cluster_storage_vnic_type | default('normal') }}"
  }
}
{% endif %}

#####
##### Cluster nodes
#####

# Declare a local value based on the metadata, so we can trigger a rebuild from it
# By default, changing the metadata just updates the metadata on the current instance
# However because of how we use metadata, we want to trigger a rebuild
locals {
  instance_metadata = {
    zenith_volume_id = "${openstack_blockstorage_volume_v3.zenith_volume.id}"
    data_volume_id = "${openstack_blockstorage_volume_v3.data_volume.id}"
    zenith_registrar_url = "{{ zenith_registrar_url }}"
    zenith_registrar_token_ssh = "{{ zenith_token_ssh }}"
    zenith_registrar_token_webconsole = "{{ zenith_token_webconsole }}"
    zenith_registrar_token_monitoring = "{{ zenith_token_monitoring }}"
    zenith_fqdn_webconsole = "{{ zenith_fqdn_webconsole }}"
    zenith_fqdn_monitoring = "{{ zenith_fqdn_monitoring }}"
    zenith_sshd_host = "{{ zenith_sshd_host }}"
    zenith_sshd_port = "{{ zenith_sshd_port }}"
    azimuth_cloud_name = "notused"
    azimuth_user_name = "${data.openstack_identity_auth_scope_v3.scope.user_name}"
    azimuth_user_id = "${data.openstack_identity_auth_scope_v3.scope.user_id}"
    azimuth_project_name = "${data.openstack_identity_auth_scope_v3.scope.project_name}"
    azimuth_project_id = "${data.openstack_identity_auth_scope_v3.scope.project_id}"
    {% for playbook in ansible_init_playbooks %}
    ansible_init_pb_{{ loop.index0 }}_name = "{{ playbook.name }}"
    {% if playbook.stage is defined %}
    ansible_init_pb_{{ loop.index0 }}_stage = "{{ playbook.stage }}"
    {% endif %}
    {% endfor %}
    {% for collection in ansible_init_collections %}
    ansible_init_coll_{{ loop.index0 }}_name = "{{ collection.name }}"
    ansible_init_coll_{{ loop.index0 }}_type = "{{ collection.type }}"
    ansible_init_coll_{{ loop.index0 }}_version = "{{ collection.version }}"
    {% if collection.source is defined %}
    ansible_init_coll_{{ loop.index0 }}_source = "{{ collection.source }}"
    {% endif %}
    {% endfor %}
    trigger_rebuild = "2"
  }
}

# A data resource that changes when the metadata changes
# We can use this to trigger a rebuild of the server
resource "terraform_data" "instance_metadata" {
  input = local.instance_metadata
}

resource "openstack_compute_instance_v2" "cluster_server" {
  name      = "{{ cluster_name }}-{{ cluster_type }}"
  image_id  = "{{ cluster_image }}"
  flavor_id = "{{ cluster_flavor }}"

  network {
    port = openstack_networking_port_v2.cluster.id
  }

  {% if cluster_storage_network is defined %}
  network {
    port = openstack_networking_port_v2.cluster_storage.id
  }
  {% endif %}

  user_data = <<-EOF
  #cloud-config
  user:
    ssh_authorized_keys:
      - {{ cluster_deploy_ssh_public_key }}
{% if cluster_user_ssh_public_key is defined and cluster_user_ssh_public_key %}
  users:
  - name: azimuth
    ssh_authorized_keys:
      - {{ cluster_user_ssh_public_key }}
{% endif %}
  EOF

  metadata = local.instance_metadata

  # Rebuild the server when the metadata changes
  lifecycle {
    replace_triggered_by = [terraform_data.instance_metadata]
  }
}

resource "openstack_compute_volume_attach_v2" "zenith_volume" {
  instance_id = "${openstack_compute_instance_v2.cluster_server.id}"
  volume_id   = "${openstack_blockstorage_volume_v3.zenith_volume.id}"
}

resource "openstack_compute_volume_attach_v2" "data_volume" {
  instance_id = "${openstack_compute_instance_v2.cluster_server.id}"
  volume_id   = "${openstack_blockstorage_volume_v3.data_volume.id}"
}

{% if cluster_floating_ip_address is defined and cluster_floating_ip_address %}
#####
##### Floating IP association
#####

resource "openstack_networking_floatingip_associate_v2" "cluster_floatingip_assoc" {
  floating_ip = "{{ cluster_floating_ip_address }}"
  port_id = "${openstack_networking_port_v2.cluster.id}"
}
{% endif %}
